#数据挖掘和数据清洗
#所谓数据挖掘就是获取信息，所谓数据清洗，就是整理信息
#
#通用爬虫和聚焦爬虫
#通用爬虫
#常见的就是搜索引擎，比如百度，谷歌之类的。
#所以我们说通用爬虫就是搜索引擎提取系统的重要组成部分，主要目的是将互联网上的网页下载到本地形成一个互联网内容的景象备份
#第一步抓取网页，然后是保存数据，接着是预处理，最后提供检索服务
#通用爬虫很多无用信息
#聚焦爬虫
#需要进行专门的代码编写，同样的，效率极高
#我们学的就是聚焦爬虫
#
#请求和响应
#服务器主要有三部分，分别是前端，中间层，以及数据库
#前端是网页的展现，中间层负责数据的处理，数据库保存数据。
#用户通过浏览器发送请求到前端，然后由中间层处理数据，最后从数据库里调出相应数据，最后再通过前端返回数据，这个过程叫响应
#
#通过百度搜索Python
#https://www.baidu.com/s?wd=Python&rsv_spt=1&rsv_iqid=0xd855f
#df70007aed7&issp=1&f=8&rsv_bp=1&rsv_idx=2&ie=utf-8&tn=980120
#88_5_dg&ch=12&rsv_enter=1&rsv_dl=tb&rsv_sug3=2&rsv_sug1=1&rs
#v_sug7=100&rsv_sug2=0&inputT=3040&rsv_sug4=5974&rsv_sug=2
#
#后面的都不需要，我们只保留有用的
#https://www.baidu.com/s?wd=Python&
#前面的部分是网址，也就是URL(统一资源定位符)，是用于完整描述Internet上网页和其他资源的地址的一种标识方法。
#
#URL
#URL(统一资源定位符)，是用于完整描述Internet上网页和其他资源的地址的一种标识方法。
#URL的结构
#scheme:协议(例如http,https,ftp等)
#host:服务器的IP地址或者域名(www.baidu.com这种就是，只不过是解析过的，pv4或者pv6)
#port：服务器的端口(如果是默认端口，端口号在浏览器中默认为80，故不显示)
#path：访问资源的路径
#query_string:参数，发送给http服务器的数据(例如上文的wd=Python)
#anchor:锚(跳转到网页的制定锚点位置)，就是再次打开网页时自动回到上次的阅读位置
#
#https  ://  www.baidu.com  /s ?  wd=Python&
#协议是https，IP是www.baidu.com，端口号是80(未显示)，s是访问路径的一部分，
#参数为wd=Python参数之间一般用&隔开，所有参数之前用问号进行表示
#
#GET请求和POST请求
#请求方式有两种，一个是GET请求，一个是POST请求
#get是从服务器上获取数据，post是向服务器传送数据
#get请求参数显示，都显示在URL上，所以get请求的参数是URL的一部分
#例如密码之类的都会显示在上面，所以为了保证信息，就实行了另外一种方式叫post请求。
#post请求参数在请求体中，消息长度没有限制，而且以隐形方式进行发送，通常用来向http服务器提交量比较大的数据，和隐私数据